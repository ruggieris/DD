{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "<b>Author:</b> <a href=\"http://pages.di.unipi.it/ruggieri/\">Salvatore Ruggieri</a><br/>\n",
    "<b>Python version:</b>  3.x<br/>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir:  ../\n"
     ]
    }
   ],
   "source": [
    "# if using Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    is_colab = True\n",
    "    wdir = 'https://raw.githubusercontent.com/ruggieris/DD/main/'\n",
    "    # required modules\n",
    "    !pip install lime\n",
    "    !pip install dalex\n",
    "    !pip install shap\n",
    "    !pip install pydotplus\n",
    "except:\n",
    "    is_colab = False\n",
    "    wdir = '../' # local files\n",
    "print('Working dir: ', wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydotplus\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#import graphviz\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "#import graphviz\n",
    "import os\n",
    "\n",
    "# add if Graphviz is not already in the path\n",
    "if True:\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "adult = pd.read_csv(wdir+\"data/adult_continuous.csv\", sep=',', na_values='?')\n",
    "# remove columns\n",
    "del adult['fnlwgt'] \n",
    "del adult['native-country'] \n",
    "# impute missing/outlier values\n",
    "adult['workclass'] = adult['workclass'].fillna(adult['workclass'].mode()[0])\n",
    "adult['occupation'] = adult['occupation'].fillna(adult['occupation'].mode()[0])\n",
    "adult.loc[ adult['capital-gain']==99999, 'capital-gain']= int(adult['capital-gain'].mean())\n",
    "# target class\n",
    "target = 'class'\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values into numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat = adult.select_dtypes('object').columns\n",
    "df = pd.DataFrame()\n",
    "encoders = dict()\n",
    "for col in adult.columns:\n",
    "    if col in cat:\n",
    "        col_encoder = LabelEncoder()\n",
    "        df[col] = col_encoder.fit_transform(adult[col])\n",
    "        df[col] = df[col].astype('category')\n",
    "        encoders[col] = col_encoder\n",
    "    else:\n",
    "        df[col] = adult[col]\n",
    "print(encoders['class'].classes_)\n",
    "# categorical and numerical and predictive atts \n",
    "categorical = [c for c in cat if c!=target]\n",
    "cat2pos = {f:i for i, f in enumerate(df.columns) if f in categorical} \n",
    "categorical_pos = list(cat2pos.values()) # categorical variable positions\n",
    "numerical = [c for c in df.columns if c!=target and c not in set(categorical)]\n",
    "atts = [c for c in df.columns if c!=target]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocess = ColumnTransformer([(\"enc\", OneHotEncoder(), categorical_pos)], remainder = 'passthrough')\n",
    "\n",
    "preprocess.fit(df[atts])\n",
    "# decode back column names\n",
    "def mapf(f):\n",
    "    if f[:3]=='rem':\n",
    "        return f[11:]\n",
    "    f = f[5:]\n",
    "    pos = f.find('_')\n",
    "    return f[:pos]+'='+encoders[f[:pos]].classes_[int(f[pos+1:])]\n",
    "\n",
    "\n",
    "print(preprocess.get_feature_names_out())\n",
    "fnames = [mapf(f) for f in preprocess.get_feature_names_out() if f!=target]\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black box model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "bb = make_pipeline(preprocess, GradientBoostingClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Global model explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training-test split 60%-40%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([target], axis=1)\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black box training\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "bb.fit(X_train.values, y_train) # .values for numpy as to prevent warning later on\n",
    "y_pred = bb.predict(X_test.values)\n",
    "print('Accuracy: {:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('F1-score: {:.4f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate model assuming to know the training data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "sm = make_pipeline(preprocess, DecisionTreeClassifier(max_depth=3))\n",
    "sm.fit(X_train, bb.predict(X_train))\n",
    "sm_pred = sm.predict(X_test)\n",
    "print('Accuracy: {:.4f}'.format(accuracy_score(y_test, sm_pred)))\n",
    "print('F1-score: {:.4f}'.format(f1_score(y_test, sm_pred)))\n",
    "print('Fidelity: {:.4f}'.format(accuracy_score(y_pred, sm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize surrogate model\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "\n",
    "dot_data = tree.export_graphviz(sm[1], out_file=None, feature_names=fnames, \n",
    "             class_names=encoders['class'].classes_, filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate model assuming NOT to know the training data\n",
    "# use half of the test data for training surrogate model\n",
    "half = int(len(X_test)/2) \n",
    "X_surr_train = X_test[:half]\n",
    "X_surr_test = X_test[half:]\n",
    "sm.fit(X_surr_train, bb.predict(X_surr_train))\n",
    "\n",
    "sm_pred = sm.predict(X_surr_test)\n",
    "print('Accuracy: {:.4f}'.format(accuracy_score(y_test[half:], sm_pred)))\n",
    "print('F1-score: {:.4f}'.format(f1_score(y_test[half:], sm_pred)))\n",
    "print('Fidelity: {:.4f}'.format(accuracy_score(y_pred[half:], sm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize surrogate model\n",
    "dot_data = tree.export_graphviz(sm[1], out_file=None, feature_names=fnames,  \n",
    "             class_names=encoders['class'].classes_, filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Outcome explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# LimeTabularExplainer \n",
    "lime_explainer = LimeTabularExplainer(X_test.to_numpy(), # numpy dataset\n",
    "                    feature_names=X_test.columns, # column names\n",
    "                    class_names=encoders['class'].classes_,  # class names\n",
    "                    categorical_features=categorical_pos,\n",
    "                    categorical_names={cat2pos[f]:encoders[f].classes_ for f in categorical}, # categorical variable value names\n",
    "                    discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain instance\n",
    "x = X_test.iloc[3]\n",
    "print(x)\n",
    "predict_fn = lambda x: bb.predict_proba(x).astype(float)\n",
    "exp = lime_explainer.explain_instance(x, predict_fn)\n",
    "# as attribute, weight\n",
    "exp.local_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Break-down plots\n",
    "import dalex as dx\n",
    "\n",
    "exp = dx.Explainer(bb, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# explaning an instance\n",
    "x = X_test.iloc[3].values\n",
    "bd_inst = exp.predict_parts(x, type='break_down')\n",
    "# plotted as attribute=<int>, to get attribute=<value> need to re-train on adult instead of df\n",
    "bd_inst.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP using Dalex\n",
    "shap = exp.predict_parts(x, type = 'shap', B=5)\n",
    "shap.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP package\n",
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "predict_fn = lambda x: bb.predict_proba(x)[:, 1]\n",
    "med = np.median(X_test, axis=0).reshape((1, X_test.shape[1]))\n",
    "shap_explainer = shap.KernelExplainer(predict_fn, med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_test.iloc[3].values\n",
    "shap_values_single = shap_explainer.shap_values(x)\n",
    "shap.force_plot(shap_explainer.expected_value, shap_values_single, features=x, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_explainer(X_test.iloc[3:4])\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(shap_explainer.expected_value, shap_explainer.shap_values(X_test[:1000]), X_test.columns, ignore_warnings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceteris Paribus plots using Dalex\n",
    "cp = exp.predict_profile(x)\n",
    "cp.plot(variables=numerical, variable_type = \"numerical\")\n",
    "cp.plot(variables=categorical, variable_type = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model inspection: PDP\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "# age\n",
    "PartialDependenceDisplay.from_estimator(bb, X_test, ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICE\n",
    "PartialDependenceDisplay.from_estimator(bb, X_test, ['age'], kind='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDP plot using DALEX\n",
    "pdp = exp.model_profile(type='partial', variables=['age'])\n",
    "pdp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
