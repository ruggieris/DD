{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "<b>Author:</b> <a href=\"http://pages.di.unipi.it/ruggieri/\">Salvatore Ruggieri</a><br/>\n",
    "<b>Python version:</b>  3.x<br/>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir:  ../\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # if using Colab\n",
    "    import google.colab\n",
    "    is_colab = True\n",
    "    wdir = 'https://raw.githubusercontent.com/ruggieris/DD/main/'\n",
    "    # create folder src if it does not exists\n",
    "    !mkdir -p src\n",
    "    # download source\n",
    "    !wget --no-cache --backups=1 -O src/dd.py {wdir}'src/dd.py'\n",
    "except:\n",
    "    is_colab = False\n",
    "    wdir = '../' # local files\n",
    "print('Working dir: ', wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# required modules (under Anaconda use: > conda install -c conda-forge <package>)\n",
    "if is_colab:\n",
    "    !pip install pyroaring\n",
    "    !pip install pyfim \n",
    "    !pip install lightgbm\n",
    "    !pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('src/' if is_colab else '../src/') # local path\n",
    "import dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: independence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lt_0</td>\n",
       "      <td>le_17d6</td>\n",
       "      <td>critical_or_other_existing_credit</td>\n",
       "      <td>radio_or_tv</td>\n",
       "      <td>le_38848d8</td>\n",
       "      <td>no_known_savings</td>\n",
       "      <td>ge_7</td>\n",
       "      <td>gt_2d8</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>gt_52d6</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>from_1d6_le_2d2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>le_1d2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from_0_lt_200</td>\n",
       "      <td>gt_31d2</td>\n",
       "      <td>existing_paid</td>\n",
       "      <td>radio_or_tv</td>\n",
       "      <td>from_38848d8_le_7519d6</td>\n",
       "      <td>lt_100</td>\n",
       "      <td>from_1_lt_4</td>\n",
       "      <td>from_1d6_le_2d2</td>\n",
       "      <td>female_div_or_dep_or_mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>le_30d2</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>le_1d6</td>\n",
       "      <td>skilled</td>\n",
       "      <td>le_1d2</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_checking</td>\n",
       "      <td>le_17d6</td>\n",
       "      <td>critical_or_other_existing_credit</td>\n",
       "      <td>education</td>\n",
       "      <td>le_38848d8</td>\n",
       "      <td>lt_100</td>\n",
       "      <td>from_4_lt_7</td>\n",
       "      <td>from_1d6_le_2d2</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>from_41d4_le_52d6</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>le_1d6</td>\n",
       "      <td>unskilled_resident</td>\n",
       "      <td>gt_1d2</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lt_0</td>\n",
       "      <td>gt_31d2</td>\n",
       "      <td>existing_paid</td>\n",
       "      <td>furniture_or_equipment</td>\n",
       "      <td>from_7519d6_le_11154d4</td>\n",
       "      <td>lt_100</td>\n",
       "      <td>from_4_lt_7</td>\n",
       "      <td>from_1d6_le_2d2</td>\n",
       "      <td>male_single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life_insurance</td>\n",
       "      <td>from_41d4_le_52d6</td>\n",
       "      <td>none</td>\n",
       "      <td>for_free</td>\n",
       "      <td>le_1d6</td>\n",
       "      <td>skilled</td>\n",
       "      <td>gt_1d2</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lt_0</td>\n",
       "      <td>from_17d6_le_31d2</td>\n",
       "      <td>delayed_previously</td>\n",
       "      <td>new_car</td>\n",
       "      <td>from_38848d8_le_7519d6</td>\n",
       "      <td>lt_100</td>\n",
       "      <td>from_1_lt_4</td>\n",
       "      <td>gt_2d8</td>\n",
       "      <td>male_single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no_known_property</td>\n",
       "      <td>gt_52d6</td>\n",
       "      <td>none</td>\n",
       "      <td>for_free</td>\n",
       "      <td>from_1d6_le_2d2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>gt_1d2</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status           duration                     credit_history  \\\n",
       "0            lt_0            le_17d6  critical_or_other_existing_credit   \n",
       "1   from_0_lt_200            gt_31d2                      existing_paid   \n",
       "2     no_checking            le_17d6  critical_or_other_existing_credit   \n",
       "3            lt_0            gt_31d2                      existing_paid   \n",
       "4            lt_0  from_17d6_le_31d2                 delayed_previously   \n",
       "\n",
       "                  purpose           credit_amount    savings_status  \\\n",
       "0             radio_or_tv              le_38848d8  no_known_savings   \n",
       "1             radio_or_tv  from_38848d8_le_7519d6            lt_100   \n",
       "2               education              le_38848d8            lt_100   \n",
       "3  furniture_or_equipment  from_7519d6_le_11154d4            lt_100   \n",
       "4                 new_car  from_38848d8_le_7519d6            lt_100   \n",
       "\n",
       "    employment installment_commitment           personal_status other_parties  \\\n",
       "0         ge_7                 gt_2d8               male_single          none   \n",
       "1  from_1_lt_4        from_1d6_le_2d2  female_div_or_dep_or_mar          none   \n",
       "2  from_4_lt_7        from_1d6_le_2d2               male_single          none   \n",
       "3  from_4_lt_7        from_1d6_le_2d2               male_single     guarantor   \n",
       "4  from_1_lt_4                 gt_2d8               male_single          none   \n",
       "\n",
       "   ... property_magnitude                age other_payment_plans   housing  \\\n",
       "0  ...        real_estate            gt_52d6                none       own   \n",
       "1  ...        real_estate            le_30d2                none       own   \n",
       "2  ...        real_estate  from_41d4_le_52d6                none       own   \n",
       "3  ...     life_insurance  from_41d4_le_52d6                none  for_free   \n",
       "4  ...  no_known_property            gt_52d6                none  for_free   \n",
       "\n",
       "  existing_credits                 job num_dependents own_telephone  \\\n",
       "0  from_1d6_le_2d2             skilled         le_1d2           yes   \n",
       "1           le_1d6             skilled         le_1d2          none   \n",
       "2           le_1d6  unskilled_resident         gt_1d2          none   \n",
       "3           le_1d6             skilled         gt_1d2          none   \n",
       "4  from_1d6_le_2d2             skilled         gt_1d2          none   \n",
       "\n",
       "  foreign_worker class  \n",
       "0             no  good  \n",
       "1             no   bad  \n",
       "2             no  good  \n",
       "3             no  good  \n",
       "4             no   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data: credit.csv, adult.csv or any other dataset with discrete columns only.\n",
    "df = pd.read_csv(wdir+'data/credit_discrete.csv', sep=',', na_values='?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Context ALL\n",
      "Size = 1000  Perc = 100.00%\n",
      "                     |class=bad|class=good|   \n",
      "age=gt_52d6          |       29|        67| 96\n",
      "age=from_41d4_le_52d6|       39|       122|161\n",
      "                     |       68|       189|257\n",
      "RD = 0.059847\n",
      "-----\n",
      "Context ALL\n",
      "Size = 1000  Perc = 100.00%\n",
      "                     |class=bad|class=good|   \n",
      "age=le_30d2          |      148|       263|411\n",
      "age=from_41d4_le_52d6|       39|       122|161\n",
      "                     |      187|       385|572\n",
      "RD = 0.117861\n",
      "-----\n",
      "Context ALL\n",
      "Size = 1000  Perc = 100.00%\n",
      "                     |class=bad|class=good|   \n",
      "age=from_30d2_le_41d4|       84|       248|332\n",
      "age=from_41d4_le_52d6|       39|       122|161\n",
      "                     |      123|       370|493\n",
      "RD = 0.010776\n",
      "-----\n",
      "Context ALL\n",
      "Size = 1000  Perc = 100.00%\n",
      "                      |class=bad|class=good|    \n",
      "age!=from_41d4_le_52d6|      261|       578| 839\n",
      "age=from_41d4_le_52d6 |       39|       122| 161\n",
      "                      |      300|       700|1000\n",
      "RD = 0.068849\n"
     ]
    }
   ],
   "source": [
    "# DD(filename or dataframe, unprotected item, negative decision)\n",
    "#disc = dd.DD(df, 'foreign_worker=no', 'class=bad')\n",
    "disc = dd.DD(df, unprotectedItem='age=from_41d4_le_52d6', predBadItem='class=bad')\n",
    "for ctg in disc.ctg_global():\n",
    "    disc.print(ctg)\n",
    "    print(\"RD = {:f}\".format(ctg.rd()))\n",
    "ctg = disc.ctg_any()\n",
    "disc.print(ctg)\n",
    "print(\"RD = {:f}\".format(ctg.rd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering condition: return None to filter out, or measure value\n",
    "# contingency table ctg such that ctg.n() >= minSupp \n",
    "'''\n",
    "     contingency table for independence\n",
    "     =========== pred.pos === pred.neg === \n",
    "     protected       a            b       n1()\n",
    "     unprotected     c            d       n2()\n",
    "     ===========    m1()  ===    m2()  ==  n()\n",
    "'''\n",
    "def check_rd(ctg):\n",
    "    # at least 20 protected with pred.pos and p2() > 0\n",
    "    if ctg.a < 20 or ctg.c==0:\n",
    "        return None\n",
    "    return ctg.rd()\n",
    "\n",
    "def check_rr(ctg):\n",
    "    # at least 20 protected with pred.pos and p2() > 0\n",
    "    if ctg.a < 20 or ctg.c==0:\n",
    "        return None\n",
    "    return ctg.rr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contingency tables: \n",
    "# minSupp = min support of context (negative = absolute, positive = percentage)\n",
    "# topk = top k contingency tables\n",
    "ctgs_rd = disc.extract(testCond=check_rd, minSupp=-20, topk=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Context duration=gt_31d2 AND existing_credits=from_1d6_le_2d2 AND foreign_worker=no\n",
      "Size = 60  Perc = 6.00%\n",
      "                     |class=bad|class=good|  \n",
      "age=le_30d2          |       21|         6|27\n",
      "age=from_41d4_le_52d6|        1|         4| 5\n",
      "                     |       22|        10|32\n",
      "RD = 0.577778\n",
      "-----\n",
      "Context duration=gt_31d2 AND existing_credits=from_1d6_le_2d2\n",
      "Size = 60  Perc = 6.00%\n",
      "                     |class=bad|class=good|  \n",
      "age=le_30d2          |       21|         6|27\n",
      "age=from_41d4_le_52d6|        1|         4| 5\n",
      "                     |       22|        10|32\n",
      "RD = 0.577778\n",
      "-----\n",
      "Context purpose=new_car AND personal_status=female_div_or_dep_or_mar AND credit_amount=le_38848d8 AND foreign_worker=no\n",
      "Size = 57  Perc = 5.70%\n",
      "                     |class=bad|class=good|  \n",
      "age=le_30d2          |       20|         8|28\n",
      "age=from_41d4_le_52d6|        1|         4| 5\n",
      "                     |       21|        12|33\n",
      "RD = 0.514286\n"
     ]
    }
   ],
   "source": [
    "# print top 3 \n",
    "for v, ctg in ctgs_rd[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"RD = {:f}\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contingency tables wrt RR\n",
    "ctgs_rr = disc.extract(testCond=check_rr, minSupp=-20, topk=1000)\n",
    "for v, ctg in ctgs_rr[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"RR = {:f}\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contingency tables in ctgs_rd\n",
    "ct_rd_set = set(ctg[1] for ctg in ctgs_rd)\n",
    "# contingency tables in ctgs_rd\n",
    "ct_rr_set = set(ctg[1] for ctg in ctgs_rr)\n",
    "# contingency tables in both\n",
    "shared = ct_rd_set & ct_rr_set\n",
    "len(shared) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot p1() vs p2()\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.plot([ctg.p1() for ctg in shared], [ctg.p2() for ctg in shared], '+', color='red', label=r'RR $\\cap$ RD')\n",
    "only_rd = ct_rd_set - shared\n",
    "plt.plot([ctg.p1() for ctg in only_rd], [ctg.p2() for ctg in only_rd], '.', color='blue', label=r'RD \\ RR')\n",
    "only_rr = ct_rr_set - shared\n",
    "plt.plot([ctg.p1() for ctg in only_rr], [ctg.p2() for ctg in only_rr], 'x', color='green', label=r'RR \\ RD')\n",
    "plt.legend()\n",
    "plt.xlabel('p1')\n",
    "plt.ylabel('p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sequential covering algorithm: 10 contingency tables\n",
    "covers, residuals, times, uncovered, ctg, ctg_rem = disc.cover_n(ct_rd_set, check_rd, 10)\n",
    "print('Total protected covered:', sum(residuals))\n",
    "print('Total protected:', sum(residuals)+len(uncovered))\n",
    "print('% covered: {:.2f}%'.format(100*sum(residuals)/(sum(residuals)+len(uncovered))))\n",
    "disc.print(ctg)\n",
    "print(\"RD = {:f}\".format(ctg.rd()))\n",
    "disc.print(ctg_rem)\n",
    "print(\"RD = {:f}\".format(ctg_rem.rd()))\n",
    "for ctg, res in zip(covers, residuals):\n",
    "    print('-----\\nCovered', res)\n",
    "    disc.print(ctg)\n",
    "    print(\"RD = {:f}\".format(ctg.rd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "adult = pd.read_csv(wdir+'data/adult_discrete.csv', sep=',', na_values='?')\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values\n",
    "enc = dd.Encode()\n",
    "df = enc.fit_transform(adult)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are missing values (but LightGBM deal with them! no need for imputation methods)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df has categorical features (but LightGBM deal with them! no need for one-hot encoding)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test\n",
    "X = df[df.columns.drop('class')]\n",
    "y = df['class'].astype(int)\n",
    "X_train, X_test, y_train, y_test, adult_train, adult_test = train_test_split(X, y, adult.copy(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model and make predictions \n",
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "# add predicted class in the adult_test (decoding back)\n",
    "adult_test['predicted'] = [enc.decode['class'][v] for v in clf.predict(X_test)]\n",
    "adult_test['predicted'].astype('category')\n",
    "# add predicted score in the adult_test\n",
    "adult_test['score'] = clf.predict_proba(X_test)[:,1]\n",
    "adult_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrimination in overall test set\n",
    "atts = list(set(adult_test.columns)-set(['score'])) # do not use score in contexts\n",
    "disc = dd.DD(adult_test[atts], unprotectedItem='race=White', predBadItem='predicted=-50K', codes=dict(),\n",
    "                                                 trueBadItem='class=-50K', na_values={'nan'}) \n",
    "for ctg in disc.ctg_global():\n",
    "    disc.print(ctg)\n",
    "    print(\"TNR White = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TNR NonWhite = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(ctg.eop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering condition: return None to filter out, or measure value\n",
    "# contingency table ctg such that ctg.n() >= minSupp \n",
    "'''\n",
    "     contingency table for separation\n",
    "          protected                                   unprotected\n",
    "     ========== pred.pos == pred.neg ===      === pred.pos  == tpred.neg === \n",
    "     true.pos    TPp          FNp      Pp()          TPu          FNu        Pu()\n",
    "     true.neg    FPp          TNp      Np()          FPu          TNu        Nu()\n",
    "     ==========   a     =====  b  ===  n1()   ===      c    ====    d   ===  n2()\n",
    "'''\n",
    "def check_eop(ctg):\n",
    "    # at least 20 protected with pred.pos and p2() > 0\n",
    "    if ctg.Pu() < 20 or ctg.Pp() < 20 or ctg.Np()==0 or ctg.Nu()==0:\n",
    "        return None\n",
    "    return ctg.eop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contingency tables: \n",
    "ctgs_eop = disc.extract(testCond=check_eop, minSupp=-100, topk=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output top 3\n",
    "for v, ctg in ctgs_eop[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"TNR White = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TNR NonWhite = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential covering algorithm: 10 contingency tables\n",
    "covers, residuals, times, uncovered, ctg, ctg_rem = disc.cover_n([ctg for _,ctg in ctgs_eop], check_eop, 10)\n",
    "print('Total protected covered:', sum(residuals))\n",
    "print('Total protected:', sum(residuals)+len(uncovered))\n",
    "print('% covered: {:.2f}%'.format(100*sum(residuals)/(sum(residuals)+len(uncovered))))\n",
    "disc.print(ctg)\n",
    "print(\"EOP = {:f}\".format(ctg.eop()))\n",
    "disc.print(ctg_rem)\n",
    "print(\"EOP = {:f}\".format(ctg_rem.eop()))\n",
    "\n",
    "for ctg, res in zip(covers, residuals):\n",
    "    print('-----\\nCovered', res)\n",
    "    disc.print(ctg)\n",
    "    print(\"TPR White = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TPR NonWhite = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(ctg.eop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairlearn algorithms and utils (https://github.com/fairlearn/fairlearn)\n",
    "# or try your preferred fair ML tool\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "# fairness by post-processing\n",
    "postprocess_est = ThresholdOptimizer(estimator=clf, constraints=\"true_negative_rate_parity\", prefit=True, predict_method='predict')\n",
    "X_train = X_train.fillna(0) # fairlearn does not manage missing values\n",
    "X_test = X_test.fillna(0) # fairlearn does not manage missing values\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=X_train['race'])\n",
    "# fair-corrected predictions \n",
    "adult_test['predicted'] = [enc.decode['class'][v] for v in postprocess_est.predict(X_test, sensitive_features=X_test['race']).astype(int)]\n",
    "adult_test['predicted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrimination in test set\n",
    "disc = dd.DD(adult_test[atts], unprotectedItem='race=White', predBadItem='predicted=-50K', codes=dict(),\n",
    "                                                 trueBadItem='class=-50K', na_values={'nan'}) \n",
    "for ctg in disc.ctg_global():\n",
    "    disc.print(ctg)\n",
    "    print(\"TNR Male = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TNR Female = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(ctg.eop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contingency tables: \n",
    "ctgs_eop_post = disc.extract(testCond=check_eop, minSupp=-100, topk=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, ctg in ctgs_eop_post[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"TNR White = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TNR NonWhite = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.kdeplot(np.array([v for v, _ in ctgs_eop]), bw_adjust=1.0, color='b')\n",
    "sns.kdeplot(np.array([v for v, _ in ctgs_eop_post]), bw_adjust=1.0, color='r')\n",
    "plt.legend(labels=['before', 'after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential covering algorithm: 10 contingency tables\n",
    "covers, residuals, times, uncovered, ctg, ctg_rem = disc.cover_n([ctg for _,ctg in ctgs_eop_post], check_eop, 10)\n",
    "print('Total protected covered:', sum(residuals))\n",
    "print('Total protected:', sum(residuals)+len(uncovered))\n",
    "print('% covered: {:.2f}%'.format(100*sum(residuals)/(sum(residuals)+len(uncovered))))\n",
    "disc.print(ctg)\n",
    "print(\"EOP = {:f}\".format(ctg.eop()))\n",
    "disc.print(ctg_rem)\n",
    "print(\"EOP = {:f}\".format(ctg_rem.eop()))\n",
    "\n",
    "for ctg, res in zip(covers, residuals):\n",
    "    print('-----\\nCovered', res)\n",
    "    disc.print(ctg)\n",
    "    print(\"TNR White = {:f}\".format(ctg.tnru()))\n",
    "    print(\"TNR NonWhite = {:f}\".format(ctg.tnrp()))\n",
    "    print(\"EOP = {:f}\".format(ctg.eop()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering condition: return None to filter out, or measure value\n",
    "# contingency table ctg such that ctg.n() >= minSupp \n",
    "'''\n",
    "     confusion matrix\n",
    "     =========== pred.pos === pred.neg === \n",
    "     true.pos        a            b       n1()\n",
    "     true.neg        c            d       n2()\n",
    "     ===========    m1()  ===    m2()  ==  n()\n",
    "'''\n",
    "def check_err(ctg):\n",
    "    return (ctg.b+ctg.c)/ctg.n()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors in test set\n",
    "disc = dd.DD(adult_test, unprotectedItem='class=-50K', predBadItem='predicted=+50K', codes=dict(), na_values={'nan'}) \n",
    "for ctg in disc.ctg_global():\n",
    "    disc.print(ctg)\n",
    "    print(\"ERR = {:f}\".format(check_err(ctg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contingency tables: \n",
    "ctgs_err = disc.extract(testCond=check_err, minSupp=-100, topk=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3\n",
    "for v, ctg in ctgs_err[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"ERR = {:f}\".format(check_err(ctg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_err2(ctg):\n",
    "    n = ctg.n()\n",
    "    return (ctg.b+ctg.c)/n if n>100 else None\n",
    "\n",
    "covers, residuals, times, uncovered, ctg, ctg_rem = disc.cover_n([ctg for _,ctg in ctgs_err], check_err2, 10)\n",
    "print('Total protected covered:', sum(residuals))\n",
    "print('Total protected:', sum(residuals)+len(uncovered))\n",
    "print('% covered: {:.2f}%'.format(100*sum(residuals)/(sum(residuals)+len(uncovered))))\n",
    "disc.print(ctg)\n",
    "print(\"ERR = {:f}\".format(check_err(ctg)))\n",
    "disc.print(ctg_rem)\n",
    "print(\"ERR = {:f}\".format(check_err(ctg_rem)))\n",
    "for ctg, res in zip(covers, residuals):\n",
    "    print(res)\n",
    "    disc.print(ctg)\n",
    "    print(\"ERR = {:f}\".format(check_err(ctg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering condition: return None to filter out, or measure value\n",
    "# contingency table ctg such that ctg.n() >= minSupp \n",
    "'''\n",
    "     contingency table for inference (protected=None, n1=a,n2=c)\n",
    "     ===========\n",
    "     true.pos      a             \n",
    "     true.neg      c             \n",
    "     ===========   m1()\n",
    "'''\n",
    "def check_acc(ctg):\n",
    "    n = ctg.m1()\n",
    "    return max(ctg.a,ctg.c)/n if n>0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy in training set\n",
    "disc = dd.DD(adult_train, 'class=-50K', codes=dict(), na_values={'nan'}) \n",
    "for ctg in disc.ctg_global():\n",
    "    disc.print(ctg)\n",
    "    print(\"ACC = {:f}\".format(check_acc(ctg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contingency tables: \n",
    "ctgs_acc = disc.extract(testCond=check_acc, minSupp=-1000, topk=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, ctg in ctgs_acc[:3]:\n",
    "    disc.print(ctg)\n",
    "    print(\"ACC = {:f}\".format(check_acc(ctg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD: boundary kernel limiting to (0.0, 1.0)\n",
    "sns.kdeplot(np.array([v for v, _ in ctgs_acc]), bw_adjust=1.0, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
